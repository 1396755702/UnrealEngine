Availability:Public
Title:文字エンコード
Crumbs: %ROOT%, Engine, Programming, Programming/Basics
Description:アンリアル・エンジン 4で使用する文字エンコードの概要

[TOC(start:2)]

## 概要

このドキュメントはアンリアルで使用する文字のエンコードの概要を説明します。

あらかじめ必要な知識： [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)](http://www.joelonsoftware.com/articles/Unicode.html)



## テキストフォーマット

テキストと文字列を表現するには、いくつかのフォーマットを使用します。これらのフォーマットと、フォーマット特有の良い点と悪い点を把握することにより、プロジェクトに使用するフォーマットの決定に役立てることができます。

フォーマットの技術的定義ではありませんが、このドキュメント適した簡易なバージョンとなっています。

$ **ASCII** ： 32と126（32と126を含む）の間の文字、および0、9、10、13です。（P4タイプのテキスト）（チェックイン時にP4のトリガーで検証済みです）
$ **ANSI** :ASCIIと現行コードページです（例えばWestern European high ASCII）（P4サーバーにバイナリとして格納しなくてはいけません）
$ **UTF-8** ： 8ビットで構成される文字列です。非ANSI文字の生成に特別な文字のシーケンスを使用できます（ASCIIのスーパーセット）（P4タイプのUnicode）
$ **UTF-16** ： [BOM]（http://en.wikipedia.org/wiki/Byte-order_mark）付きで1文字を16ビットで構成するする文字列です。（アストラル文字は32ビットまで可能）（P4タイプのUTF-16）（チェックインの際にP4トリガーで検証されます） 


### バイナリの例

| **良い点** | **悪い点** |
| --- | --- |
| 内部フォーマットが定義されていません。フォーマットに関係なく各ファイルを読み込むことができます。 | マージできません。このタイプの全てのファイルは排他的チェックアウトが必要です。 |
| | 内部フォーマットが定義されていません。それぞれのファイルが異なるフォーマットになる場合もあります。|
| | P4は各バージョンを全て格納します。デポのサイズが必要以上に大きくなる要因となります。 |


### テキストの例

| **良い点** | **悪い点** |
| --- | --- |
| マージが可能です。排他的なチェックアウトは必要ありません。 | とても限定的で、ASCII文字のみを許容します。 |


### UTF-8の例

| **良い点** | **悪い点** |
| --- | --- |
| 必要に応じて全ての文字に簡単にアクセスできます。 | アジア系言語に対し別のメモリプロファイルがあります。 |
| より少ないメモリ消費量です。| P4タイプのUnicodeはPerforceサーバーでは有効ではありません。 |
| ASCIIのスーパーセットです。 単純なASCII文字列は、完全に有効なUTF-8文字列です。| 文字列操作がより複雑です。 長さの計算のような簡単な操作さえも文字列をパースしなくてはいけません。|
| ゲームが文字列をASCIIと認識しても機能し、そのように出力をします。 |アジア地域では、 MSDevはASCII以外は上手く処理することができません。これがチェックイン時にテキストをASCIIとして検証する理由です。 |
| Unicodeが有効になっているサーバーの場合、ファイルのマージが可能で排他的なチェックアウトは必要ありません。 | |
| パースして文字列がUTF-8かどうかを検知することができます（BOMの有無に関係なく） | |


### UTF-16の例

| **良い点** | **悪い点** |
| --- | --- |
| 必要に応じて全ての文字に簡単にアクセスできます。 | メモリの使用量が多くなります。 |
|簡単です。メモリの使用量は文字数の2倍になります（弊社が使用する文字は全て[Basic Multilingual Plane](http://en.wikipedia.org/wiki/Mapping_of_Unicode_character_planes))にあります。 | BOMが無い場合はこのフォーマットの検知は困難です。 |
|簡単です。文字列操作は文字列をパースせずに分割/結合することができます。 | ゲームが文字列をASCIIと検知した時は機能せず、その由を出力します（UTF-16検証ソフトでチェックイン時に検証が可能になりました）。 |
| ゲームで使用しているフォーマットと同じです。平行移動、パース、メモリ操作は必要ありません。 | MSDevはアジア地域では、ASCII以外は何も処理しません。 これがチェックイン時にテキストをASCIIとして検証する理由です。 |
| マージが可能です。排他的なチェックアウトは必要ありません。 | |
| C# 内部でUTF-16を使用します。 | |



## UE4の内部文字列の表現

アンリアルエンジン4の全文字列は、FStringsやTCHAR配列などの[UTF-16](http://en.wikipedia.org/wiki/UTF-16/UCS-2) フォーマットでメモリに格納しています。多くのコードが2バイトを1コードポイントと想定しているため、基本多言語プレーン（Basic Multilingual Plane：BMP）のみをサポートしています。アンリアルの内部エンコーディングはUCS-2として記述するのがより正確です。文字列は現行プラットフォームのエンディアンネス（メモリ上でのバイトの並び）に適した方法で格納されます。

ディスクにパッケージもしくはディスクからパッケージへシリアル化する場合、0xffより小さいTCHAR文字は全て（8ビット）バイト列として格納されます。それ以外は2バイトのUTF-16文字列として格納されます。　シリアライズコードは、必要に応じていかなるエンディアン変換も処理することができます。



## UE4でロードするテキストファイル

Unrealが外部のテキストファイルをロードする時は（例えばランタイム時の「.INT」ファイルの読み込み）、ほとんどの場合、「UnMisc.cpp」にあるappLoadFileToString()関数で処理します。主な処理は、appBufferToString()関数で行います。

この関数は、UTF-16ファイルにあるUnicodeのバイトオーダーマーク(BOM)を読み取り、もしBOMがあれば、そのファイルをUTF-16ファイルとしてビッグエンディアン順もしくはリトルエンディアン順で読み込みます。 

BOMが存在しなかった場合の挙動はプラットフォームに依存します。 

Windowsでは、デフォルトのWindows MBCSエンコーディングを使用してテキストをUTF-16に変換して（米国英語および西ヨーロッパは[Windows-1252](http://en.wikipedia.org/wiki/Windows-1252)、韓国語はCP949、日本語はCP932）、MultiByteToWideChar(CP_ACP, MB_ERR_INVALID_CHARS...)を使用します。これは2009年7月頃のQAビルドで追加されました。

Windows以外のプラットフォームで変換に失敗した場合、関数は単にそれぞれのバイトを読み込み、TCHARの配列を作成するために読み込んだものを16ビットに埋め込みます。

appLoadFileToString()関数でロードした、UTF-8でエンコードされたテキストファイルを検出またはデコードするコードはないことに留意してください。



## アンリアルで保存したテキストファイル

エンジンによって生成されるテキストファイルの多くは、appSaveStringToFile()関数を利用して保存します。

TCHAR型の文字がすべてシングルバイトで表されている文字列は、（8-bit）1バイト列として格納されます。もしくはbAlwaysSaveAsAnsiフラグがtrueで渡されない限り、UTF-16として格納されます。その場合、まずデフォルトのWindowsエンコーディング形式に変換されます。　シェーダーコンパイラが抱えるUTF-16ファイルに関する問題を回避するため、現時点ではシェーダーファイルのみで実行されます。



## アンリアルで使用するテキストファイルに推奨されるエンコーディング


### 「INT」と「INI」ファイル

どちらかのバイトオーダー順のUTF-16です。デフォルトのアジア言語用のMBCS文字（例えばCP932）がWindows上で機能する一方で、これらのファイルをPS3とXbox360プラットフォームへロードする必要があり、変換コードはWindowsのみで実行されます。


### ソースコード
一般的に、C++ ソースコード内部への文字列リテラルの格納は推奨しておらず、このデータを「INT」ファイルに格納することを推奨します。 


#### C++ソースコード

UTF-8またはデフォルトのWindowsの符号化です。MSVC、Xbox360 コンパイラ、gcc はすべて、UTF-8で符号化されたソースファイルで問題ないはずです。例えば著作権、商標、「度」のシンボルのような高いビット セットの文字を持つ Latin-1 で符号化されたファイルは、ソースコードでは可能な限り避けるべきです。これは、異なるロケールを持つシステム上で符号化が壊れるためです。　サードパーティのソフトウェアでのいくつかの事例は回避不可能 （例：著作権表示）なので、MSVC に関しては、警告 4819 を無効化します。これは、アジアのWindowsでコンパイルを行う際に起こる警告です。



## UTF-16テキストファイルをPerforceに格納する


* 「テキスト」を使用 **しない** でください。
    * UTF-x ファイルがチェックインされている状態でテキストとして格納すると、同期後にファイルは破損します。
* 「バイナリ」を使用する場合、ファイルを排他的チェックアウトとして印をつけてください。
    * ASCII、UTF-8、UTF-16文字コードとしてチェックインが可能で、これらはエンジンで機能します。 
    * しかしながら、バイナリファイルはマージすることができないので、ファイルが排他的チェックアウトとマークされていない場合は変更は無視されます。
* 'UTF-16' を使用する場合、UTF-16以外のファイルがチェックインされない様に注意してください。
    *  Perforceには、非UTF-16をUTF-16 としてチェックインすることを許可しないトリガーがあります。 
        * 「//depot/UnrealEngine3/Development/Tools/P4Utils/CheckUTF16/」
* 'Unicode' タイプはUTF-8を用いて変換し、ここでは主な使い道はありません。




## 変換ルーチン

さまざまな符号化へ、またさまざまな符号化から文字列を変換する多くのマクロがあります。これらのマクロは、ローカル スコープで宣言されたクラスインスタンスを使用し、スタック上でスペースを割り当てるため、これらへのポインタを保持しないことが非常に重要です。関数呼び出しへ文字列を渡すためだけに使用します。


* TCHAR_TO_ANSI(str)
* TCHAR_TO_OEM(str) 
* ANSI_TO_TCHAR(str)
* TCHAR_TO_UTF8(str)
* UTF8_TO_TCHAR(str)


「UnStringConv.h」ファイルから以下のヘルパクラスを使用します。


* typedef TStringConversion<TCHAR,ANSICHAR,FANSIToTCHAR_Convert> FANSIToTCHAR;
* typedef TStringConversion<ANSICHAR,TCHAR,FTCHARToANSI_Convert> FTCHARToANSI;
* typedef TStringConversion<ANSICHAR,TCHAR,FTCHARToOEM_Convert> FTCHARToOEM;
* typedef TStringConversion<ANSICHAR,TCHAR,FTCHARToUTF8_Convert> FTCHARToUTF8;
* typedef TStringConversion<TCHAR,ANSICHAR,FUTF8ToTCHAR_Convert> FUTF8ToTCHAR;


TCHAR_TO_ANSI の使用時は、バイト数がTCHAR文字列の長さと同じになると仮定しないことが重要です。複数バイトの文字セットは、TCHAR文字ごとに複数バイトを必要とすることがあります。最終的な文字列の長さをバイトで知りたい場合は、マクロの代わりにヘルパ クラスを使用することができます。例:


    
    FString String;
    ...
    FTCHARToANSI Convert(*String);
    Ar->Serialize((ANSICHAR*)Convert, Convert.Length());  // FTCHARToANSI::Length() はnullターミネータを除いて、符号化された文字列のバイト数を返します。
    





## UnicodeでToUpper()とToLower()が難しい問題

UE4は、現時点でANSIのみを処理します  (ASCII | コードページ 1252 | | 西ヨーロッパ)

全言語において、不本意ながらも他よりはましな方法はこちらで参照してください　「http://en.wikipedia.org/wiki/ISO/IEC_8859」


* 英語、フランス語、ドイツ語、イタリア語、ポルトガル語、スペインとメキシコのスペイン語両方はISO/IEC 8859-1です。 
* ポーランド語、チェコ語、ハンガリー語はISO/IEC 8859-2 です。
* ロシア語はISO/IEC 8859-5です。


「ftp://ftp.unicode.org/Public/MAPPINGS/ISO8859/」からのマッピングは、上記の言語に対応する変換ルールが含まれています。 「大文字」や「小文字」情報は、期待通りの結果を得るために、適切なUnicode文字をクロスリファレンスします。



## 東アジア系言語の符号化に特有なC++ソースコードに関する注意事項

UTF-8およびデフォルトのWindowsエンコーディングは、C++コンパイラに以下のような問題が生じる可能性があります。

**デフォルトのWindowsによる符号化** 
  
CP932(日本語)、CP936(簡体字中国語)、CP950(繁体字中国語)などの東アジア系言語のダブルバイト文字エンコード形式がソースコードに含まれている場合は、シングルバイト文字のコードページ(米国のCP437など)を使用して動作するWindows上でC++によるソースコードをコンパイルする際に注意が必要です。

東アジア系文字のエンコードシステムは、最初のバイトには0x81から0xFEまでが使用され、2番目のバイトには0x40から0xFEまでが使用されます。2番目のバイトの値0x5Cは、ASCII/latin-1ではバックスラッシュとして処理され、C++言語では特別な意味を持ちます。（文字列リテラル内ではエスケープシークエンスの意味。また、行末での使用は、行の継続を意味します）。   
そのようなソースコードを、シングルバイトコードページをもつWindowsでコンパイルする場合、コンパイラは、東アジア系言語のダブルバイト文字の符号化を無視します。その結果、コンパイルエラーが起きるか、最悪の場合はEXEファイルでバグが発生します。

シングルラインコメント：  
東アジア系言語のコメントに0x5cが入っている場合は、行の欠落が生じるために、発見が難しいバグやエラーが生じる原因となります。

    
        // EastAsianCharacterCommentThatContains0x5cInTheEndOfComment0x5c'\'
        important_function(); /* this line would be connected to above line as part of comment */
    



文字列リテラル内：  
0x5cエスケープシーケンスとして認識するために、文字列の破損またはエラーが生じる原因となります。

    
        printf("EastAsianCharacterThatContains0x5c'\'AndIfContains0x5cInTheEndOfString0x5c'\'");
        function();
        printf("Compiler recognizes left double quotation mark in this line as the end of string literal that continued from first line, and expected this message is C++ code.");
    


0x5cに続く文字が実際にエスケープシーケンスを指定する場合、コンパイラは、このエスケープシーケンス文字のセットを指定された単一文字に変換します。  
（エスケープシーケンスの指定がない場合は、動作結果は実装時の定義に依存することになります。ただし、MSVCでは、0x5cが取り除かれ、"unrecognized character escape sequence" （エスケープシーケンスとして正しく認識できません）という警告が表示されます。）  
上記の例は、文字列の最後に0x5cバックスラッシュがあり、次の文字がダブルクオーテーションマークです。そのため、このエスケープシーケンス「\"」は、文字列データの中で1つのダブルクオーテーションマークに変換され、コンパイラは次のダブルクオーテーションマークが出てくるか、ファイルの終わりに達するまで、文字列データが生成され続け、エラーが発生します。

危険な文字の例：  
CP932 （日本語 Shift-JIS）の「表」という文字のコードは、0x955Cです。CP932では、多くの文字に0x5Cが入っています。  
CP936（簡体字中国語 GBK）において、「乗」という文字は0x815Cです。CP936では、多くの文字に0x5Cが入っています。  
CP950 （繁体字中国語 Big5）において、「功」という文字は0xA55Cです。CP950では、多くの文字に0x5Cが入っています。  
CP949 （韓国語 EUC-KR）は問題ありません。EUC-KRでは、2番目のバイトに0x5Cが使用されないためです。

__BOMが付いていないUTF-8 __ （一部のテキストエディタはBOMをシグネチャと呼びます）
  
東アジア系言語をUTF-8として格納しているソースコードは、Windows CP949（韓国語）、CP932（日本語）、CP936（簡体字中国語）、CP950(繁体字中国語)上でC++ソースコードのコンパイルをする際は注意が必要です。

UTF-8文字エンコードは東アジア系文字に3バイト使用します。 0xE0から0xEFまでが第1バイトに、0x80から0xBFまでが第2バイトに、0x80から0xBFまでが第3バイトに割り当てられています。BOMが付いていない場合、東アジア言語系Windowsのデフォルトのエンコーディングでは、UTF-8でエンコードされた3バイトとその次に続く1バイトを、2バイトの東アジア系エンコード文字が2つあるものとして認識してしまいます。具体的には、第1バイトと第2バイトを合わせて第1の東アジア系文字として認識し、第3バイトとその後に続く1バイト分を2つ目の東アジア系文字として認識するのです。  
UTF-8でエンコードされた3バイトに続く文字が、文字列リテラルもしくはコメントにおいて特別な意味がある場合に問題が発生する可能性があります。

インラインコメントの例：  
コメントを構成するテキストに東アジア系文字が奇数個あり、次に続く文字がコメント終了の記号である場合、コードが欠落してしまうため、発見しづらいバグやエラーが生じます。

    
        /*OddNumberOfEastAsianCharacterComment*/
        important_function();
        /*normal comment*/
    


東アジア系言語のコードページを使用したWindows上のコンパイラは、UTF-8でデコードされた東アジア系文字からなるコメントの最後に置かれた1バイトとアスタリスク(*)を、1つの東アジア系文字として認識し、その次の文字もコメントの一部として扱ってしまいます。上記の例では、コンパイラはimportant_function()関数をコメントの一部として除去してしまうのです。  
この動作はたいへん危険なものでありながら、同時に、この欠落したコードを発見することは難しいのです。

シングルラインコメント：  
バックラッシュ（\）が東アジア系言語によるコメントの最後に置かれた場合、行が欠落しないため発見が難しいバグやエラーが発生します。

    
        // OddNumberOfEastAsianCharacterComment\
        description(); /* coder intended this line as comment, by using backslash at the end of above line */
    


プログラマは、コメントの最後に意図的なバックラッシュ（\）を置く必要がないため、これは大変珍しいケースです。

文字列リテラル内部：  
文字列リテラル内に奇数個の東アジア系文字があり、次に続く文字が特別な意味をもつ記号である場合は、文字列が破損してエラーや警告が発生します。

    
        printf("OddNumberOfEastAsiaCharacterString");
        printf("OddNumberOfEastAsiaCharacterString%d",0);
        printf("OddNumberOfEastAsiaCharacterString\n");
    


東アジア系言語のコードページを使うWindowsでは、コンパイラが、UTF-8でデコードされた東アジア系文字からなる文字列の最後に置かれた1バイトとその次に置かれた1バイトを、1つの東アジア系文字として認識してしまいます。運よく、コンパイラ警告C4819（無効にしていない場合）やエラーによって問題に気がつくこともあります。そうでない場合は、文字列が破損してしまいます。

__結論__
  
UTF-8またはデフォルトのWindowsによる符号化スキームを使用することができますが、上記の問題について注意する必要があります。繰り返しになりますが、C++ソース内部で文字列リテラルの使用は推奨しません。C++ソースコード内部で東アジア系文字のコード化を使用する場合、デフォルトのコードページに必ず東アジア系のコードページを使用してください。  
その他の適切な方法として、BOM付きのUTF-8の使用があげられます（一部のテキストエディタはBOMをUnicodeシグネチャと呼びます）。

__注記__
  
2010年2月18日に、UTF-8およびUTF-16符号化スキームをいくつかのコンパイラでテストを行いました。  

PCおよびXbox 360用のMSVCや、PS3用のgccまたはslcでは、UTF-8でエンコードされたソースコード（BOMありとBOMなしの両方）をコンパイルすることができました。 
しかしUTF-16（リトルエンディアンとビッグエンディアン）は、MSVCのみがサポートしています。  

Perforceは、UTF-16とUTF-8の両方で機能しました。ただしp4 diffコマンドは、UTF-8ファイルに含まれているBOMの文字を可視化してしまいます。

外部参照リンク： [Code Pages Supported by Windows](http://msdn.microsoft.com/en-us/goglobal/bb964654.aspx)

