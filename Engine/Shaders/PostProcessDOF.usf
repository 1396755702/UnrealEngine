// Copyright 1998-2015 Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	PostProcessDOF.usf: PostProcessing Depth of Field
=============================================================================*/

#include "Common.usf"
#include "PostProcessCommon.usf"
#include "DeferredShadingCommon.usf"		// FGBufferData
#include "DepthOfFieldCommon.usf"

// todo move to central place
float ComputeDOFNearFocalMask(float SceneDepth)
{
	float NearFocalPlane = View.DepthOfFieldFocalDistance;

	return saturate((NearFocalPlane - SceneDepth) / View.DepthOfFieldNearTransitionRegion);
}

// todo move to central place
float ComputeDOFFarFocalMask(float SceneDepth)
{
	float FarFocalPlane = View.DepthOfFieldFocalDistance + View.DepthOfFieldFocalRegion;

	return saturate((SceneDepth - FarFocalPlane) / View.DepthOfFieldFarTransitionRegion);
}

// .x:far, .y:near
float2 ComputeDOFFocalMask(float SceneDepth, float SkyWithoutHorizonMask)
{
	float2 Ret = float2(ComputeDOFFarFocalMask(SceneDepth), ComputeDOFNearFocalMask(SceneDepth));

	float SkyFocusDistance = DepthOfFieldParams[0].x;

	// The skybox should not be faded out, expect in the horizon, this can be optimized
	if(SceneDepth > SkyFocusDistance)
	{
		Ret.x = lerp(Ret.x, 0,  SkyWithoutHorizonMask);
	}

	return Ret;
}


// pixel shader entry point
void SetupPS(
	float4 UVAndScreenPos : TEXCOORD0
	, out float4 OutColor0 : SV_Target0
#if ENABLE_NEAR_BLUR 
	, out float4 OutColor1 : SV_Target1
#endif
	)
{
	float2 UV = UVAndScreenPos.xy;

	float2 Offset = 0.5f * PostprocessInput0Size.zw;

	float MaskDistance = View.DepthOfFieldFocalDistance + View.DepthOfFieldFocalRegion * 0.5f;

	float4 DepthQuad = GatherSceneDepth(UV, PostprocessInput1Size.zw);

#if ENABLE_NEAR_BLUR == 0
	// We aren't writing out to the second render target, so we'll just make a dummy value here which 
	// doesn't end up going anywhere. Then, the source code can stay neat and tidy, while the compiler can still 
	// strip it out
	float4 OutColor1;
#endif

	OutColor0 = 0;
	OutColor1 = 0;

	float2 Mask;
	float4 Sample;

	// for each sample of the full res input image
	// we compute the mask (front of back layer)
	// and put into MRT0 or MRT1
	
	// screen position in [-1, 1] screen space
	float2 ScreenSpacePos = UVAndScreenPos.zw;

	// can be optimized, needed to not blur the skybox
	float3 ScreenVector = normalize(mul(float4(ScreenSpacePos, 1, 0), View.ScreenToWorld).xyz);
	float SkyWithoutHorizonMask = saturate(ScreenVector.z * 3.0f);
	
	Mask = ComputeDOFFocalMask(DepthQuad.x, SkyWithoutHorizonMask);
	Sample = float4(Texture2DSampleLevel(PostprocessInput0, PostprocessInput0Sampler, UV + Offset * float2(-1, 1), 0).rgb, 1);
	OutColor0 += Sample * Mask.x;
	OutColor1 += Sample * Mask.y;

	Mask = ComputeDOFFocalMask(DepthQuad.y, SkyWithoutHorizonMask);
	Sample = float4(Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + Offset * float2(1, 1)).rgb, 1);
	OutColor0 += Sample * Mask.x;
	OutColor1 += Sample * Mask.y;

	Mask = ComputeDOFFocalMask(DepthQuad.z, SkyWithoutHorizonMask);
	Sample = float4(Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + Offset * float2(1, -1)).rgb, 1);
	OutColor0 += Sample * Mask.x;
	OutColor1 += Sample * Mask.y;

	Mask = ComputeDOFFocalMask(DepthQuad.w, SkyWithoutHorizonMask);
	Sample = float4(Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + Offset * float2(-1, -1)).rgb, 1);
	OutColor0 += Sample * Mask.x;
	OutColor1 += Sample * Mask.y;

	// we average 4 samples
	OutColor0 /= 4;
	OutColor1 /= 4;

//	OutColor0.rgb *= float3(1,0,0);
//	OutColor1.rgb *= float3(0,1,0);
}


float4 DepthOfFieldUVLimit;

// pixel shader to combine the full res scene and the blurred images behind and in front of the the focal plane
void MainRecombinePS(
	in float4 UVAndScreenPos : TEXCOORD0,
	out float4 OutColor : SV_Target0
	)
{
	// SceneColor in full res
	float2 PixelPosCenter = UVAndScreenPos.zw * ScreenPosToPixel.xy + ScreenPosToPixel.zw + 0.5f;

	float2 FullResUV = PixelPosCenter * PostprocessInput0Size.zw;

	// DOF in half res
//	float2 ViewportUV = FullResUV * float2(1, DepthOfFieldParams[1].z);// - 0.5 * PostprocessInput1Size.zw;
//	float2 ViewportUV = (PixelPos * 0.5f + 0.5f) * PostprocessInput1Size.zw;
	float2 ViewportUV = UVAndScreenPos.xy;

	// Clamp UV to avoid pulling bad data.
	ViewportUV.x = clamp(ViewportUV.x, DepthOfFieldUVLimit.x, DepthOfFieldUVLimit.z);
	ViewportUV.y = clamp(ViewportUV.y, DepthOfFieldUVLimit.y, DepthOfFieldUVLimit.w);


	float4 SceneColorAndDepth = float4(Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, FullResUV).rgb, CalcSceneDepth(FullResUV));

	float3 UnfocusedSceneColor = SceneColorAndDepth.rgb;

	// behind focal plane
	float4 DOFAccumLayer1 = Texture2DSample(PostprocessInput1, PostprocessInput1Sampler, ViewportUV);
#if ENABLE_NEAR_BLUR
	float4 DOFAccumLayer3 = Texture2DSample(PostprocessInput2, PostprocessInput2Sampler, ViewportUV);
#else
	// I'm presuming all that matters here is the W==0 bit to mask out this value
	// TODO: Should check that compiler is doing a good job of removing the usages of this
	// from the rest of the code. It has no reason not to be able to do so...
	float4 DOFAccumLayer3 = float4(0,0,0,0); 
#endif

	float Layer1Mask = DOFAccumLayer1.a;
	float Layer2Mask = 1.0f - ComputeDOFFarFocalMask(SceneColorAndDepth.a);
//	float Layer2Mask = 1.0f - DOFAccumLayer1.a;
	float Layer3Mask = DOFAccumLayer3.a;
	float PerPixelNearMask = ComputeDOFNearFocalMask(SceneColorAndDepth.a);

	// 3 layers
	float Div0Bias = 0.0001f;

	// RGB color, A how much the full resolution showes through
	float3 LayerMerger = 0;

	// Layer 1: half res background
	LayerMerger = (UnfocusedSceneColor * Div0Bias + DOFAccumLayer1.rgb) / (DOFAccumLayer1.a + Div0Bias);

	// Needed to cope with the skybox not being blurred, the tweak value
	// avoids having a discontinuity between blurry far objects and the skybox
	// and is choosen to not produce too much blobby looking out of focus rendering.
	float Blend = DOFAccumLayer1.a;
	// Magic function to transform alpha into smooth blend function against in-focus skybox.
	Blend = sqrt(Blend);
	Blend = sqrt(Blend);
	Blend = Blend * Blend * (3.0 - 2.0 * Blend);
	LayerMerger = lerp(UnfocusedSceneColor, LayerMerger, Blend);

	// Layer 2: then we add the focused scene to fill the empty areas
	float Smash = 0.25;
	Layer2Mask = saturate((Layer2Mask - (1.0 - Smash)) * rcp(Smash));
	Layer2Mask *= Layer2Mask;
//	LayerMerger = lerp(LayerMerger, SceneColorAndDepth.rgb, Layer2Mask * (1 - PerPixelNearMask));
	LayerMerger = lerp(LayerMerger, SceneColorAndDepth.rgb, Layer2Mask);

	float3 FrontLayer = (UnfocusedSceneColor * Div0Bias + DOFAccumLayer3.rgb) / (DOFAccumLayer3.a + Div0Bias);

	// Layer 3: on top of that blend the front half res layer	
	LayerMerger = lerp(LayerMerger, FrontLayer, saturate(Layer3Mask * 5));

	OutColor.rgb = LayerMerger;
	OutColor.a = 0;
}




//
// PROTOTYPE CIRCLE DOF : WORK IN PROGRESS
//

// CIRCLE DOF: Compute circle of confusion size in pixels.
float DepthToCoc(float Depth) 
{
	float Focus = View.DepthOfFieldFocalDistance;
	float Radius = View.DepthOfFieldScale * 2.0;

	// Returning only FAR COC for now.
	return max(0.0,(Depth - Focus) / Depth) * Radius;
}

// pixel shader entry point
void CircleSetupPS(
	float4 UVAndScreenPos : TEXCOORD0
	, out float4 OutColor0 : SV_Target0
#if ENABLE_NEAR_BLUR 
	, out float4 OutColor1 : SV_Target1
#endif
	)
{
#if ENABLE_NEAR_BLUR == 0
	// We aren't writing out to the second render target, so we'll just make a dummy value here which 
	// doesn't end up going anywhere. Then, the source code can stay neat and tidy, while the compiler can still 
	// strip it out
	float4 OutColor1;
#endif

	float2 UV = UVAndScreenPos.xy;

	float4 DepthQuad = GatherSceneDepth(UV, PostprocessInput1Size.zw);

	UV = UVAndScreenPos.xy - 0.5*PostprocessInput0Size.zw;

	float4 CW = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV.xy, 0);
	float4 CZ = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV.xy, 0, int2(1,0));
	float4 CX = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV.xy, 0, int2(0,1));
	float4 CY = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV.xy, 0, int2(1,1));

	float4 CocQuad = float4(DepthToCoc(DepthQuad.x), DepthToCoc(DepthQuad.y), DepthToCoc(DepthQuad.z), DepthToCoc(DepthQuad.w));

	// Doing a max depth reduction (erode the foreground). Less correct, but less artifacts.
	// Perhaps need to re-open this in the future.

	// Stuff max radius in alpha.
	OutColor0.a = max(max(CocQuad.x,CocQuad.y),max(CocQuad.z,CocQuad.w));

	// Remove samples which are outside the size.
	// TODO: Tune the ScaleFactor.
	float ScaleFactor = 1.0;
	float4 W = float4(
		1.0-saturate((OutColor0.a - CocQuad.x) * ScaleFactor),
		1.0-saturate((OutColor0.a - CocQuad.y) * ScaleFactor),
		1.0-saturate((OutColor0.a - CocQuad.z) * ScaleFactor),
		1.0-saturate((OutColor0.a - CocQuad.w) * ScaleFactor));

	OutColor0.rgb = (1.0/(W.x+W.y+W.z+W.w)) * (CX.rgb*W.x + CY.rgb*W.y + CZ.rgb*W.z + CW.rgb*W.w);

	// TODO: Near.
	OutColor1 = 0;
}



// {0 to 1} output.
float NoizNorm(float2 N, float X)
{
	N+=X;
	return frac(sin(dot(N.xy,float2(12.9898, 78.233)))*43758.5453);
}

// {-1 to 1} output.
float NoizSnorm(float2 N, float X)
{
	return NoizNorm(N,X)*2.0-1.0;
}

float2 RotVec(float Radius, float Radians)
{
	return Radius * float2(cos(Radians), sin(Radians));
}

float2 RandomOffset;

// pixel shader entry point
void CirclePS(
	float4 UVAndScreenPos : TEXCOORD0
	, out float4 OutColor0 : SV_Target0
#if ENABLE_NEAR_BLUR 
	, out float4 OutColor1 : SV_Target1
#endif
	)
{
	float2 UV = UVAndScreenPos.xy;

#if ENABLE_NEAR_BLUR == 0
	// We aren't writing out to the second render target, so we'll just make a dummy value here which 
	// doesn't end up going anywhere. Then, the source code can stay neat and tidy, while the compiler can still 
	// strip it out
	float4 OutColor1;
#endif

	// TODO: Near.
	OutColor1 = 0.0;

	//
	// TODO: This part of the algorithm is a placeholder for something better.
	//       Current placeholder is a stochastic algorithm.
	//

	// Going to grab sets of 4 samples.
	// Each set of 4 samples can be a smaller circle of confusion
	// (aka can be in-front of the larger background).

	//
	// Pass 0
	//

	float TwoPi = 2.0 * 3.14159;

	// Grab circle of confusion for the pixel.
	OutColor0 = Texture2DSampleLevel(PostprocessInput0, PostprocessInput0Sampler, UV, 0);
	float Coc = OutColor0.a + (1.0/65536.0);

	float RadianBase = NoizSnorm(UVAndScreenPos.xy, 0.010 * RandomOffset.x) * TwoPi;
	float RadiusBase = NoizNorm(UVAndScreenPos.xy, 0.013 * RandomOffset.x) * (1.0/11.5);

	// Bring out to the smaller radius of sample sets.
	// This has the highest chance of seeing a smaller overlapping CoC.
	float R1 = (RadiusBase+9.0/11.5) * Coc;
	float R2 = (RadiusBase+3.0/11.5) * Coc;
	float R3 = (RadiusBase+6.0/11.5) * Coc;
	float R4 = (RadiusBase+0.0/11.5) * Coc;

	// Ensure at least getting different than center pixel.
	float R1a = max(1.0,R1);
	float R2a = max(1.0,R2);
	float R3a = max(1.0,R3);
	float R4a = max(1.0,R4);

	float2 UV1 = RotVec(R1a, RadianBase + TwoPi * 0.0/12.0);
	float2 UV2 = RotVec(R2a, RadianBase + TwoPi * 3.0/12.0);
	float2 UV3 = RotVec(R3a, RadianBase + TwoPi * 6.0/12.0);
	float2 UV4 = RotVec(R4a, RadianBase + TwoPi * 9.0/12.0);

	UV1 = UVAndScreenPos.xy + UV1 * PostprocessInput0Size.zw;
	UV2 = UVAndScreenPos.xy + UV2 * PostprocessInput0Size.zw;
	UV3 = UVAndScreenPos.xy + UV3 * PostprocessInput0Size.zw;
	UV4 = UVAndScreenPos.xy + UV4 * PostprocessInput0Size.zw;

	float4 C1 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV1, 0);
	float4 C2 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV2, 0);
	float4 C3 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV3, 0);
	float4 C4 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV4, 0);

	// Base weight works around the max(1.0,radius) constraint.
	// Base weight also shapes to weight higher on the outside radius.
	float W0 = 1.0 - saturate(Coc);
	float W1 = R1;
	float W2 = R2;
	float W3 = R3;
	float W4 = R4;

	// Adjusting weight to remove occluded.
	W1 *= saturate(0.0 + C1.a - R1);
	W2 *= saturate(0.0 + C2.a - R2);
	W3 *= saturate(0.0 + C3.a - R3);
	W4 *= saturate(0.0 + C4.a - R4);

	// Make sure at least something is not zero.
	W0 += 1.0/65536.0;

	float Coc2 = Coc;
	if(W1 > 0.0) Coc2 = min(Coc2, C1.a);
	if(W2 > 0.0) Coc2 = min(Coc2, C2.a);
	if(W3 > 0.0) Coc2 = min(Coc2, C3.a);
	if(W4 > 0.0) Coc2 = min(Coc2, C4.a);

	OutColor0.rgb = OutColor0.rgb * W0 + C1.rgb * W1 + C2.rgb * W2 + C3.rgb * W3 + C4.rgb * W4;

	float Weight = W0+W1+W2+W3+W4;

	float3 Background = OutColor0.rgb * (1.0/Weight);


	//
	// Pass 1
	//

	// Drop weight of existing pass if Coc changes too much.
	float Drop = (1.0/65536.0) + 1.0 - saturate(abs(Coc - Coc2));
	OutColor0.rgb *= Drop;
	Weight *= Drop;

	R1 = (RadiusBase+10.0/11.5) * Coc2;
	R2 = (RadiusBase+ 4.0/11.5) * Coc2;
	R3 = (RadiusBase+ 7.0/11.5) * Coc2;
	R4 = (RadiusBase+ 1.0/11.5) * Coc2;

	R1a = max(1.0,R1);
	R2a = max(1.0,R2);
	R3a = max(1.0,R3);
	R4a = max(1.0,R4);

	UV1 = RotVec(R1a, RadianBase + TwoPi *  8.0/12.0);
	UV2 = RotVec(R2a, RadianBase + TwoPi * 11.0/12.0);
	UV3 = RotVec(R3a, RadianBase + TwoPi *  2.0/12.0);
	UV4 = RotVec(R4a, RadianBase + TwoPi *  5.0/12.0);

	UV1 = UVAndScreenPos.xy + UV1 * PostprocessInput0Size.zw;
	UV2 = UVAndScreenPos.xy + UV2 * PostprocessInput0Size.zw;
	UV3 = UVAndScreenPos.xy + UV3 * PostprocessInput0Size.zw;
	UV4 = UVAndScreenPos.xy + UV4 * PostprocessInput0Size.zw;

	C1 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV1, 0);
	C2 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV2, 0);
	C3 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV3, 0);
	C4 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV4, 0);

	C1.rgb = lerp(C1.rgb, Background.rgb, saturate(C1.a - Coc2));
	C2.rgb = lerp(C2.rgb, Background.rgb, saturate(C2.a - Coc2));
	C3.rgb = lerp(C3.rgb, Background.rgb, saturate(C3.a - Coc2));
	C4.rgb = lerp(C4.rgb, Background.rgb, saturate(C4.a - Coc2));

	W1 = R1;
	W2 = R2;
	W3 = R3;
	W4 = R4;

	// Adjusting weight to remove occluded.
	W1 *= saturate(0.0 + C1.a - R1);
	W2 *= saturate(0.0 + C2.a - R2);
	W3 *= saturate(0.0 + C3.a - R3);
	W4 *= saturate(0.0 + C4.a - R4);

	float Coc3 = Coc2;
	if(W1 > 0.0) Coc3 = min(Coc3, C1.a);
	if(W2 > 0.0) Coc3 = min(Coc3, C2.a);
	if(W3 > 0.0) Coc3 = min(Coc3, C3.a);
	if(W4 > 0.0) Coc3 = min(Coc3, C4.a);

	OutColor0.rgb += C1.rgb * W1 + C2.rgb * W2 + C3.rgb * W3 + C4.rgb * W4;
	Weight += W1+W2+W3+W4;




	//
	// Pass 2
	//

	// Drop weight of existing pass if Coc changes too much.
	Drop = (1.0/65536.0) + 1.0 - saturate(abs(Coc2 - Coc3));
	OutColor0.rgb *= Drop;
	Weight *= Drop;

	R1 = (RadiusBase+11.0/11.5) * Coc3;
	R2 = (RadiusBase+ 5.0/11.5) * Coc3;
	R3 = (RadiusBase+ 8.0/11.5) * Coc3;
	R4 = (RadiusBase+ 2.0/11.5) * Coc3;

	R1a = max(1.0,R1);
	R2a = max(1.0,R2);
	R3a = max(1.0,R3);
	R4a = max(1.0,R4);

	UV1 = RotVec(R1a, RadianBase + TwoPi *  4.0/12.0);
	UV2 = RotVec(R2a, RadianBase + TwoPi *  7.0/12.0);
	UV3 = RotVec(R3a, RadianBase + TwoPi * 10.0/12.0);
	UV4 = RotVec(R4a, RadianBase + TwoPi *  1.0/12.0);

	UV1 = UVAndScreenPos.xy + UV1 * PostprocessInput0Size.zw;
	UV2 = UVAndScreenPos.xy + UV2 * PostprocessInput0Size.zw;
	UV3 = UVAndScreenPos.xy + UV3 * PostprocessInput0Size.zw;
	UV4 = UVAndScreenPos.xy + UV4 * PostprocessInput0Size.zw;

	C1 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV1, 0);
	C2 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV2, 0);
	C3 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV3, 0);
	C4 = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UV4, 0);

	C1.rgb = lerp(C1.rgb, Background.rgb, saturate(C1.a - Coc3));
	C2.rgb = lerp(C2.rgb, Background.rgb, saturate(C2.a - Coc3));
	C3.rgb = lerp(C3.rgb, Background.rgb, saturate(C3.a - Coc3));
	C4.rgb = lerp(C4.rgb, Background.rgb, saturate(C4.a - Coc3));

	W1 = R1;
	W2 = R2;
	W3 = R3;
	W4 = R4;

	// Adjusting weight to remove occluded.
	W1 *= saturate(0.0 + C1.a - R1);
	W2 *= saturate(0.0 + C2.a - R2);
	W3 *= saturate(0.0 + C3.a - R3);
	W4 *= saturate(0.0 + C4.a - R4);

	OutColor0.rgb += C1.rgb * W1 + C2.rgb * W2 + C3.rgb * W3 + C4.rgb * W4;
	Weight += W1+W2+W3+W4;

	OutColor0.rgb *= (1.0/Weight);

}


// pixel shader to combine the full res scene and the blurred images behind and in front of the the focal plane
void MainCircleRecombinePS(
	in float4 UVAndScreenPos : TEXCOORD0,
	out float4 OutColor : SV_Target0
	)
{
	// Circle of confusion size for the pixel.
	float PixDepth = CalcSceneDepth(UVAndScreenPos.xy);
	float PixCoc = DepthToCoc(PixDepth) * 2.0; // 2x because full instead of half resolution.

	// Fetch 2 samples mirrored around the pixel 
	// which is stochastically distributed to fill out the circle of confusion.
	// TODO: Fix the "random values".
	// The sqrt(sqrt()) is to shape toward higher weight on the CoC edge.
	float2 UV = UVAndScreenPos.xy * PostprocessInput0Size.xy;
	float RadianBase = NoizNorm(UVAndScreenPos.xy, 0.010 * RandomOffset.x) * 3.14159 * 2.0;
	float RadiusJitter = NoizNorm(UVAndScreenPos.xy, 0.013 * RandomOffset.x);
	float2 VP = RotVec(float2(PixCoc*sqrt(sqrt(RadiusJitter)), 0.0), RadianBase) * PostprocessInput0Size.zw;

	// These two samples will still have jitter induced artifacts (very limited utility).
	// These two samples will also have bleeding artifacts.
	float4 CA = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UVAndScreenPos.xy + VP, 0);
	float4 CB = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, UVAndScreenPos.xy - VP, 0);
	OutColor = (CA + CB) * 0.5;

	// Grab the half resolution neighborhood to remove the artifacts from the full resolution output.
	// Nearest location.
	float2 HUVBase = UVAndScreenPos.xy * PostprocessInput1Size.xy - 0.5;
	float2 HUVFrac = frac(HUVBase);
	float2 HUV = (trunc(HUVBase) + 0.5) * PostprocessInput1Size.zw;

	// Load four nearest samples.
	float4 H0 = PostprocessInput1.SampleLevel(PostprocessInput1Sampler, HUV, 0);
	float4 H1 = PostprocessInput1.SampleLevel(PostprocessInput1Sampler, HUV, 0, int2(1,0));
	float4 H2 = PostprocessInput1.SampleLevel(PostprocessInput1Sampler, HUV, 0, int2(0,1));
	float4 H3 = PostprocessInput1.SampleLevel(PostprocessInput1Sampler, HUV, 0, int2(1,1));

	// TODO: This would work a lot better in YUV style colorspace?
	// Limit the full resolution to remove jitter artifacts.
	float4 HMax = max(max(H0,H1),max(H2,H3));
	float4 HMin = min(min(H0,H1),min(H2,H3));

	// Blend in the limited version quickly to remove HDR jitter artifacts and noise.
	float4 OutLimited = min(max(OutColor,HMin),HMax);
	OutColor = lerp(OutColor, OutLimited, saturate(PixCoc*PixCoc*8.0));
}


